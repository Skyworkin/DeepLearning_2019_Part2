{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 8 Making Relu / Initialization \n",
    "\n",
    "<img src=\"https://snag.gy/Uy9qxS.jpg\" style=\"width:700px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_lesson81 import *\n",
    "from exp.nb_lesson82 import *\n",
    "\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
    "\n",
    "def near(a,b): \n",
    "    return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
    "\n",
    "def test_near(a,b): \n",
    "    test(a,b,near)\n",
    "    \n",
    "\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    Loads the MNIST data from before\n",
    "    \"\"\"\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, m, s): \n",
    "    \"\"\"\n",
    "    Normalizes an input array\n",
    "    Subtract the mean and divide by standard dev\n",
    "    result should be mean 0, std 1\n",
    "    \"\"\"\n",
    "    return (x-m)/s\n",
    "\n",
    "def test_near_zero(a,tol=1e-3): \n",
    "    assert a.abs()<tol, f\"Near zero: {a}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the MNIST data and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original mean and std: tensor(0.1304) tensor(0.3073)\n",
      "normalized mean and std: tensor(0.0001) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "x_train, y_train, x_valid, y_valid = get_data()\n",
    "\n",
    "# calculate the mean and standard deviation\n",
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "print(\"original mean and std:\", train_mean,train_std)\n",
    "\n",
    "# normalize the values\n",
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_valid = normalize(x_valid, train_mean, train_std)\n",
    "\n",
    "# check the updated values\n",
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "print(\"normalized mean and std:\", train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to ensure that mean is near zero\n",
    "test_near_zero(x_train.mean())\n",
    "\n",
    "# check to ensure that std is near zero\n",
    "test_near_zero(1-x_train.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the training data\n",
    "\n",
    "Note the size of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.sh