{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_lib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()\n",
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "nh, bs = 50, 512\n",
    "c = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short intro: if you can get a small batch going fairly going well, you are off to a good start for super convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_learner(model_func, loss_func, data):\n",
    "    return Learner(*model_func(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_learner(get_model, loss_func, data)\n",
    "run = Runner([AvgStatsCallback([accuracy])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.69311296875, tensor(0.7930)]\n",
      "valid: [0.3344400146484375, tensor(0.9039)]\n",
      "train: [0.297352734375, tensor(0.9134)]\n",
      "valid: [0.2290689697265625, tensor(0.9360)]\n",
      "train: [0.23737439453125, tensor(0.9318)]\n",
      "valid: [0.19877386474609374, tensor(0.9448)]\n"
     ]
    }
   ],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.7548671875, tensor(0.7975)]\n",
      "valid: [0.355202783203125, tensor(0.9003)]\n",
      "train: [0.3477811328125, tensor(0.8997)]\n",
      "valid: [0.291547705078125, tensor(0.9151)]\n",
      "train: [0.294677890625, tensor(0.9154)]\n",
      "valid: [0.2694351806640625, tensor(0.9209)]\n"
     ]
    }
   ],
   "source": [
    "learn = create_learner(partial(get_model, lr=0.3), loss_func, data)\n",
    "run = Runner([AvgStatsCallback([accuracy])])\n",
    "\n",
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_model_func(lr=0.5): \n",
    "    return partial(get_model, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealing\n",
    "\n",
    "We define two new callbacks: the Recorder to save track of the loss and our scheduled learning rate, and a ParamScheduler that can schedule any hyperparameter as long as it's registered in the state_dict of the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recorder(Callback):\n",
    "    \"\"\"\n",
    "    This is to assist in visualizing what is happening\n",
    "    There's a lot of learning rates (could be different for)\n",
    "    each groups\n",
    "    \"\"\"\n",
    "    def begin_fit(self): self.lrs,self.losses = [],[]\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
    "        self.losses.append(self.loss.detach().cpu())        \n",
    "\n",
    "    def plot_lr  (self):\n",
    "        plt.plot(self.lrs)\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.losses)\n",
    "\n",
    "\n",
    "class ParamScheduler(Callback):\n",
    "    \"\"\"\n",
    "    Schedules any parameter, learning rate / dropout / weight decay etc.\n",
    "    \"\"\"\n",
    "    _order=1\n",
    "    def __init__(self, pname, sched_func): \n",
    "        self.pname, self.sched_func = pname, sched_func\n",
    "\n",
    "    def set_param(self):\n",
    "        \n",
    "        # param_groups (layer groups)\n",
    "        # loop through different groups of layers\n",
    "        for pg in self.opt.param_groups:\n",
    "\n",
    "            # float of how far we are through training\n",
    "            pg[self.pname] = self.sched_func(self.n_epochs/self.epochs)\n",
    "            \n",
    "    def begin_batch(self): \n",
    "        if self.in_train: \n",
    "            self.set_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple linear schedule going from start to end. It returns a function that takes a `pos` argument (going from 0 to 1) such that this function goes from `start` (at `pos=0`) to `end` (at `pos=1`) in a linear fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sched_lin(start, end):\n",
    "    \"\"\"\n",
    "    THis is a function that will return a function\n",
    "    \"\"\"\n",
    "    def _inner(start, end, pos): \n",
    "        return start + pos*(end-start)\n",
    "    \n",
    "    # returns a function that only takes position\n",
    "    return partial(_inner, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decorators\n",
    "\n",
    "This is an example of a decorator, so it can be used for any number of times. A decorator is a function that returns a function. It will pass the following function into the `@` related function. When defining custom decorators, make sure to return another function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def annealer(f):\n",
    "    def _inner(start, end): \n",
    "        return partial(f, start, end)\n",
    "    return _inner\n",
    "\n",
    "@annealer\n",
    "def sched_lin(start, end, pos): \n",
    "    return start + pos*(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift-tab works too, in Jupyter!\n",
    "# sched_lin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = sched_lin(1,2)\n",
    "f(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@annealer\n",
    "def sched_cos(start, end, pos): \n",
    "    \"\"\"\n",
    "    returns a cosine\n",
    "    \"\"\"\n",
    "    return start + (1 + math.cos(math.pi*(1-pos))) * (end-start) / 2\n",
    "\n",
    "@annealer\n",
    "def sched_no(start, end, pos):\n",
    "    \"\"\"\n",
    "    Always returns start\n",
    "    \"\"\"\n",
    "    return start\n",
    "\n",
    "@annealer\n",
    "def sched_exp(start, end, pos): \n",
    "    return start * (end/start) ** pos\n",
    "\n",
    "#This monkey-patch is there to be able to plot tensors\n",
    "torch.Tensor.ndim = property(lambda x: len(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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